{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21240\\3032578921.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpress\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_objs\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure_factory\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mff\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as ex\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.offline as pyo\n",
    "pyo.init_notebook_mode()\n",
    "sns.set_style('darkgrid')\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score as f1\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import scikitplot as skplt\n",
    "\n",
    "plt.rc('figure',figsize=(18,9))\n",
    "%pip install imbalanced-learn\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Get the path to the directory containing this script\n",
    "script_dir = os.getcwd()\n",
    "\n",
    "# Get the parent directory of the script directory\n",
    "parent_dir = os.path.dirname(script_dir)\n",
    "\n",
    "# Get the parent directory of the parent directory\n",
    "grandparent_dir = os.path.dirname(parent_dir)\n",
    "\n",
    "# Define the path to the file relative to the current working directory\n",
    "file_path = os.path.join(grandparent_dir, 'data', 'raw_data', 'churn.csv')\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Print the first few rows of the DataFrame to verify that it was loaded correctly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Group the data by the 'Attrition_Flag' column and plot a histogram of 'Months_on_book' for each group\n",
    "df.groupby('Attrition_Flag')['Months_on_book'].hist(alpha=0.5, bins=20)\n",
    "\n",
    "# Set the plot title and axis labels\n",
    "plt.title('Histogram of Months on Book by Attrition Flag')\n",
    "plt.xlabel('Months on Book')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "customer ages in our dataset follows a fairly normal distribution; thus, further use of the age feature can be done with the normality assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=2, cols=1)\n",
    "\n",
    "tr1=go.Box(x=c_data['Customer_Age'],name='Age Box Plot',boxmean=True)\n",
    "tr2=go.Histogram(x=c_data['Customer_Age'],name='Age Histogram')\n",
    "\n",
    "fig.add_trace(tr1,row=1,col=1)\n",
    "fig.add_trace(tr2,row=2,col=1)\n",
    "\n",
    "fig.update_layout(height=700, width=1200, title_text=\"Distribution of Customer Ages\")\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " we can say that genders are uniformly distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(\n",
    "    rows=2, cols=2,subplot_titles=('','<b>Platinum Card Holders','<b>Blue Card Holders<b>','Residuals'),\n",
    "    vertical_spacing=0.09,\n",
    "    specs=[[{\"type\": \"pie\",\"rowspan\": 2}       ,{\"type\": \"pie\"}] ,\n",
    "           [None                               ,{\"type\": \"pie\"}]            ,                                      \n",
    "          ]\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Pie(values=c_data.Gender.value_counts().values,labels=['<b>Female<b>','<b>Male<b>'],hole=0.3,pull=[0,0.3]),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Pie(\n",
    "        labels=['Female Platinum Card Holders','Male Platinum Card Holders'],\n",
    "        values=c_data.query('Card_Category==\"Platinum\"').Gender.value_counts().values,\n",
    "        pull=[0,0.05,0.5],\n",
    "        hole=0.3\n",
    "        \n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Pie(\n",
    "        labels=['Female Blue Card Holders','Male Blue Card Holders'],\n",
    "        values=c_data.query('Card_Category==\"Blue\"').Gender.value_counts().values,\n",
    "        pull=[0,0.2,0.5],\n",
    "        hole=0.3\n",
    "    ),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    height=800,\n",
    "    showlegend=True,\n",
    "    title_text=\"<b>Distribution Of Gender And Different Card Statuses<b>\",\n",
    ")\n",
    "\n",
    "fig.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining plot design\n",
    "def plot_design():\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('')\n",
    "    plt.yticks(fontsize=13, color='black')\n",
    "    plt.box(False)\n",
    "    plt.title(i[1], fontsize=20, color='black')\n",
    "    plt.tight_layout(pad=5.0)\n",
    "    plt.grid(b=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Select categorical variables\n",
    "categ = df.select_dtypes(include=object).columns\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize =(20, 20))\n",
    "fig.patch.set_facecolor('white')\n",
    "mpl.rcParams['font.family'] = 'Hiragino Kaku Gothic Pro'\n",
    "mpl.rcParams['font.size'] = 12\n",
    "\n",
    "colors = sns.color_palette(\"crest_r\", n_colors=7).as_hex()\n",
    "\n",
    "# Loop columns\n",
    "for i in (enumerate(categ)):\n",
    "    plt.subplot(4, 2, i[0]+1)\n",
    "    \n",
    "    if df[i[1]].value_counts().count() > 2:\n",
    "        ax = sns.countplot(y = i[1], data = df, order=df[i[1]].value_counts().index, palette=colors)\n",
    "        pct = df[i[1]].value_counts(ascending=False, normalize=True).values * 100\n",
    "        ax.bar_label(container=ax.containers[0], labels=list(map('{:.2f}%'.format,pct)), padding=3, size=12, color='black')\n",
    "        ax.grid(False)\n",
    "        ax.grid(b=None)\n",
    "        ax.xaxis.set_ticks_position('none')\n",
    "        ax.yaxis.set_ticks_position('none')\n",
    "        ax.set_xticklabels('')\n",
    "        plot_design()\n",
    "\n",
    "    else:\n",
    "        _, texts, pcts = plt.pie(\n",
    "            df[i[1]].value_counts(), \n",
    "            labels=df[i[1]].value_counts().index, \n",
    "            colors= ['#00538F', '#6AADCC'],\n",
    "            autopct='%1.1f%%', \n",
    "            wedgeprops={'linewidth': 3.0, 'edgecolor': 'white'},\n",
    "            startangle=50)\n",
    "        for pcts in pcts:\n",
    "          pcts.set_color('white')\n",
    "        plt.title(i[1], fontsize=20, color='black')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical variables\n",
    "numeric = df.select_dtypes(exclude=object).columns\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize =(20, 35))\n",
    "fig.patch.set_facecolor('white')\n",
    "mpl.rcParams['font.family'] = 'Hiragino Kaku Gothic Pro'\n",
    "mpl.rcParams['font.size'] = 12\n",
    "\n",
    "colors = sns.color_palette(\"dark\", n_colors=14).as_hex()\n",
    "\n",
    "# Loop columns\n",
    "for i in (enumerate(numeric)):\n",
    "    plt.subplot(7, 2, i[0]+1)\n",
    "    sns.kdeplot(x = i[1], data = df, color=colors[i[0]], fill=True)\n",
    "    plt.grid(b=None)\n",
    "    plot_design()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing: skew variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_limit = 0.5\n",
    "skew_vals = df[numeric].skew()\n",
    "\n",
    "skew_cols = (skew_vals\n",
    "             .sort_values(ascending=False)\n",
    "             .to_frame()\n",
    "             .rename(columns={0:'Skew'})\n",
    "             .query('abs(Skew) > {0}'.format(skew_limit)))\n",
    "\n",
    "skew_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "\n",
    "# Normalize skewed features\n",
    "for col in skew_cols.index:\n",
    "    df[col] = boxcox1p(df[col], boxcox_normmax(df[col] + 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scaling features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "for col in df[numeric]:\n",
    "    df[col] = MinMaxScaler().fit_transform(df[[col]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoding categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding\n",
    "df['Attrition_Flag'] = df['Attrition_Flag'].map({'Existing Customer': 0, 'Attrited Customer': 1})\n",
    "df['Gender'] = df['Gender'].map({'M': 0, 'F': 1})\n",
    "\n",
    "# Select categorical variables\n",
    "categ = df.select_dtypes(include=object).columns\n",
    "\n",
    "# Encoding with get dummies\n",
    "df = pd.get_dummies(df, columns=categ)\n",
    "\n",
    "# Drop columns to avoid multicollinearity\n",
    "df= df[df.columns.drop(list(df.filter(regex='Unknown')))]\n",
    "df= df[df.columns.drop(list(df.filter(regex='Platinum')))]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Upsampling Using SMOTE Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split target & features\n",
    "X = df.drop('Attrition_Flag', axis=1)\n",
    "y = df['Attrition_Flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with imbalanced dataset\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Upsampling with SMOTE algorithm\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_smote, y_smote = smote.fit_resample(X, y)\n",
    "\n",
    "print(f'''Shape of X before SMOTE: {X.shape}\n",
    "Shape of X after SMOTE: {X_smote.shape}''')\n",
    "\n",
    "print('\\nBalance of positive and negative classes (%):')\n",
    "y_smote.value_counts(normalize=True) * 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionality Reduction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using elbow-plot variance/dimensions\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(X_smote)\n",
    "\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)*100\n",
    "d = [n for n in range(len(cumsum))]\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize =(10, 10))\n",
    "fig.patch.set_facecolor('white')\n",
    "mpl.rcParams['font.family'] = 'Ubuntu'\n",
    "mpl.rcParams['font.size'] = 14\n",
    "\n",
    "ax.plot(d,cumsum, color = '#00538F', label='Cumulative Explained Variance')\n",
    "\n",
    "ax.axhline(y = 95, color='black', linestyle=':', label = '95% Explained Variance')\n",
    "ax.legend(loc='best')\n",
    "\n",
    "# Remove ticks\n",
    "ax.xaxis.set_ticks_position('none')\n",
    "ax.yaxis.set_ticks_position('none')\n",
    "\n",
    "# Remove axes splines\n",
    "for i in ['top','right']:\n",
    "    ax.spines[i].set_visible(False)\n",
    "\n",
    "# Set percentages\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "\n",
    "# annotation arrow\n",
    "arrowprops = dict(arrowstyle=\"->\", connectionstyle=\"angle3,angleA=0,angleB=-90\")\n",
    "plt.annotate('Principal Component Number 19', \n",
    "             xy=(19, 95), \n",
    "             xytext=(19+5, 95+10), \n",
    "             arrowprops=arrowprops,\n",
    "             size = 14)\n",
    "\n",
    "plt.legend(bbox_to_anchor = (1, 0.2))\n",
    "\n",
    "plt.suptitle('Explained Variance vs Dimensions', size=26)\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.xlabel('PC');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(.95) \n",
    "pca.fit(X_smote)\n",
    "\n",
    "X_pca = pca.transform(X_smote)\n",
    "X_pca = pd.DataFrame(X_pca)\n",
    "\n",
    "print(f'''Shape of X before PCA: {X_smote.shape}\n",
    "Shape of X after PCA: {X_pca.shape}''')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering: K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge y and X\n",
    "data = pd.concat([y_smote, X_pca], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means \n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km_list = list()\n",
    "\n",
    "for i in range(1,21):\n",
    "    km = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=42)\n",
    "    km = km.fit(X_pca)\n",
    "    \n",
    "    km_list.append(pd.Series({'clusters': i, \n",
    "                              'inertia': km.inertia_,\n",
    "                              'model': km}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = pd.concat(km_list, axis=1).T[['clusters','inertia']]\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize =(12, 8))\n",
    "fig.patch.set_facecolor('white')\n",
    "mpl.rcParams['font.family'] = 'Ubuntu'\n",
    "mpl.rcParams['font.size'] = 14\n",
    "\n",
    "plt.plot(k['clusters'], k['inertia'], 'bo-', color = '#00538F')\n",
    "\n",
    "# Remove ticks\n",
    "ax.xaxis.set_ticks_position('none')\n",
    "ax.yaxis.set_ticks_position('none')\n",
    "\n",
    "# Remove axes splines\n",
    "for i in ['top','right']:\n",
    "    ax.spines[i].set_visible(False)\n",
    "\n",
    "ax.set_xticks(range(0,21,2))\n",
    "ax.set(xlabel='Cluster', ylabel='Inertia');\n",
    "\n",
    "plt.suptitle('The Elbow Method: Optimal Number of Clusters', size=26);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means\n",
    "km = KMeans(n_clusters=2, random_state=42)\n",
    "km = km.fit(X_pca)\n",
    "\n",
    "data_kmeans = data.copy()\n",
    "\n",
    "data_kmeans['kmeans'] = km.predict(X_pca)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agglomerative\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "ag = AgglomerativeClustering(n_clusters=2, linkage='complete', compute_full_tree=True)\n",
    "ag = ag.fit(X_pca)\n",
    "\n",
    "data_agglom = data.copy()\n",
    "\n",
    "data_agglom['agglom'] = ag.fit_predict(X_pca)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modelling with gradient boosting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y_smote, test_size=0.3, random_state=42)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "    \n",
    "# The parameters to be fit\n",
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.125, 0.5],\n",
    "    'n_estimators':[300, 400, 500], \n",
    "    'max_depth':[7, 9, 11]       \n",
    "     }\n",
    "\n",
    "# The grid search object\n",
    "GV_GBC = GridSearchCV(GradientBoostingClassifier(random_state=42), \n",
    "                      param_grid=param_grid, \n",
    "                      scoring='f1',\n",
    "                      cv = 3,\n",
    "                      verbose=0, \n",
    "                      n_jobs=-1)\n",
    "\n",
    "# Do the grid search\n",
    "GV_GBC = GV_GBC.fit(X_train, y_train)\n",
    "print(\"best score: \", GV_GBC.best_score_)\n",
    "print(\"best param: \", GV_GBC.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = GV_GBC.best_params_\n",
    "GB = GradientBoostingClassifier(random_state=42, **best_params)\n",
    "                            \n",
    "GB = GB.fit(X_train, y_train)\n",
    "y_pred = GB.predict(X_test)\n",
    "\n",
    "print('Accuracy score: ', round(accuracy_score(y_test, y_pred), 4))\n",
    "print('F1 Score: ', round(f1_score(y_test, y_pred), 4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Means + Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split target & features\n",
    "X_kmeans = data_kmeans.drop('Attrition_Flag', axis=1)\n",
    "y_kmeans = data_kmeans['Attrition_Flag']\n",
    "\n",
    "# Split the data into training and test samples\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_kmeans, y_kmeans, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = GV_GBC.best_params_\n",
    "GB = GradientBoostingClassifier(random_state=42, **best_params)\n",
    "                            \n",
    "GB = GB.fit(X_train, y_train)\n",
    "y_pred = GB.predict(X_test)\n",
    "\n",
    "print('Accuracy score: ', round(accuracy_score(y_test, y_pred), 4))\n",
    "print('F1 Score: ', round(f1_score(y_test, y_pred), 4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "experimentations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cluster=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_kmeans' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21240\\832346736.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Cluster 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdata_kmeans0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_kmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_kmeans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'kmeans'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Split target & features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_kmeans' is not defined"
     ]
    }
   ],
   "source": [
    "# Try prediction with kmeans = 0\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Cluster 0\n",
    "data_kmeans0 = data_kmeans.loc[data_kmeans['kmeans'] == 0]\n",
    "\n",
    "# Split target & features\n",
    "X_kmeans = data_kmeans0.drop('Attrition_Flag', axis=1)\n",
    "y_kmeans = data_kmeans0['Attrition_Flag']\n",
    "\n",
    "# Split the data into training and test samples\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_kmeans, y_kmeans, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = GV_GBC.best_params_\n",
    "GB = GradientBoostingClassifier(random_state=42, **best_params)\n",
    "                            \n",
    "GB = GB.fit(X_train, y_train)\n",
    "y_pred = GB.predict(X_test)\n",
    "\n",
    "print('Accuracy score: ', round(accuracy_score(y_test, y_pred), 4))\n",
    "print('F1 Score: ', round(f1_score(y_test, y_pred), 4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cluster=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try prediction with kmeans = 1\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Cluster 1\n",
    "data_kmeans1 = data_kmeans.loc[data_kmeans['kmeans'] == 1]\n",
    "\n",
    "# Split target & features\n",
    "X_kmeans = data_kmeans1.drop('Attrition_Flag', axis=1)\n",
    "y_kmeans = data_kmeans1['Attrition_Flag']\n",
    "\n",
    "# Split the data into training and test samples\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_kmeans, y_kmeans, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = GV_GBC.best_params_\n",
    "GB = GradientBoostingClassifier(random_state=42, **best_params)\n",
    "                            \n",
    "GB = GB.fit(X_train, y_train)\n",
    "y_pred = GB.predict(X_test)\n",
    "\n",
    "print('Accuracy score: ', round(accuracy_score(y_test, y_pred), 4))\n",
    "print('F1 Score: ', round(f1_score(y_test, y_pred), 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0624f98af00d020556da11b7dcf480d829e3dfc4b6794811a6e9634b5f7901fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
